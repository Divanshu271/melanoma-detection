# Single Integrated Pipeline Architecture

## ðŸŽ¯ Overview

You have **ONE pipeline** with everything integrated into a single orchestrator script.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                           â”‚
â”‚                    main_ensemble.py (ENTRY POINT)                       â”‚
â”‚                                                                           â”‚
â”‚  âœ“ Loads data (ResNet embeddings + labels)                             â”‚
â”‚  âœ“ Sets up 5-fold Cross-Validation                                     â”‚
â”‚  âœ“ For each fold, creates HeavyEnsembleClassifier                      â”‚
â”‚  âœ“ Aggregates results across folds                                     â”‚
â”‚  âœ“ Outputs: results.json + results.csv                                 â”‚
â”‚                                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                           â”‚
                                           â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                                            â”‚
        â”‚      FOR EACH FOLD: HeavyEnsembleClassifier              â”‚
        â”‚                                                            â”‚
        â”‚  (All 3 models trained within this single class)         â”‚
        â”‚                                                            â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚                 â”‚                â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                â”‚  â”‚              â”‚  â”‚                 â”‚
        â”‚   QNN Model    â”‚  â”‚  QSVC Model  â”‚  â”‚   SVM Baseline  â”‚
        â”‚  (ResNet18     â”‚  â”‚ (Quantum     â”‚  â”‚  (Classical     â”‚
        â”‚   + 6-qubit    â”‚  â”‚  Kernel +    â”‚  â”‚   RBF on PCA)   â”‚
        â”‚   circuit +    â”‚  â”‚  RBF hybrid) â”‚  â”‚                 â”‚
        â”‚   focal loss)  â”‚  â”‚              â”‚  â”‚                 â”‚
        â”‚                â”‚  â”‚              â”‚  â”‚                 â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚                  â”‚                    â”‚
                 â”‚  Train on:        â”‚  Train on:        â”‚  Train on:
                 â”‚  âœ“ X_train        â”‚  âœ“ X_train        â”‚  âœ“ X_train
                 â”‚  âœ“ y_train        â”‚  âœ“ y_train        â”‚  âœ“ y_train
                 â”‚                  â”‚                    â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  CALIBRATION (on imbalanced VALIDATION set)     â”‚
        â”‚                                                  â”‚
        â”‚  âœ“ QNN: Platt scaling on X_val, y_val          â”‚
        â”‚  âœ“ QSVC: CalibratedClassifierCV on X_val       â”‚
        â”‚  âœ“ SVM: Platt scaling on X_val, y_val          â”‚
        â”‚                                                  â”‚
        â”‚  (Keep validation imbalanced ~11% for realism)  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  SOFT VOTING & ENSEMBLE THRESHOLD TUNING       â”‚
        â”‚                                                  â”‚
        â”‚  âœ“ Combine probabilities: (0.5*QNN_prob +       â”‚
        â”‚                              0.3*QSVC_prob +     â”‚
        â”‚                              0.2*SVM_prob)      â”‚
        â”‚                                                  â”‚
        â”‚  âœ“ Find optimal threshold on validation:        â”‚
        â”‚    - Grid search (0.0 to 1.0, 300 steps)       â”‚
        â”‚    - Objective: maximize min(precision, recall) â”‚
        â”‚    - (balanced_min mode)                        â”‚
        â”‚                                                  â”‚
        â”‚  âœ“ Store best threshold for test evaluation     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  EVALUATION ON TEST FOLD                        â”‚
        â”‚                                                  â”‚
        â”‚  âœ“ Get calibrated probabilities from all 3      â”‚
        â”‚  âœ“ Apply soft voting: (0.5*QNN + ...)          â”‚
        â”‚  âœ“ Apply learned threshold                      â”‚
        â”‚                                                  â”‚
        â”‚  âœ“ Compute metrics for:                         â”‚
        â”‚    - Individual QNN metrics                     â”‚
        â”‚    - Individual QSVC metrics                    â”‚
        â”‚    - Individual SVM metrics                     â”‚
        â”‚    - Ensemble metrics                           â”‚
        â”‚                                                  â”‚
        â”‚  Metrics: Precision, Recall, Accuracy, F1,      â”‚
        â”‚           AUC, Balanced Accuracy, Confusion Mat â”‚
        â”‚                                                  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  RECORD FOLD RESULTS                            â”‚
        â”‚                                                  â”‚
        â”‚  Store metrics for each model + ensemble        â”‚
        â”‚  Add to aggregation dictionary                  â”‚
        â”‚                                                  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AFTER ALL 5 FOLDS: AGGREGATE & REPORT                      â”‚
â”‚                                                               â”‚
â”‚  âœ“ Compute mean Â± std for all metrics across folds          â”‚
â”‚  âœ“ Final output:                                            â”‚
â”‚    - results/ensemble_results.json (detailed metrics)      â”‚
â”‚    - results/ensemble_results.csv (easy viewing)           â”‚
â”‚    - Console output: Final scores                          â”‚
â”‚                                                               â”‚
â”‚  EXPECTED OUTPUT:                                           â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚    â”‚ ENSEMBLE FINAL SCORES (5-Fold Average):            â”‚  â”‚
â”‚    â”‚ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”   â”‚  â”‚
â”‚    â”‚ Precision: 0.915 Â± 0.043                           â”‚  â”‚
â”‚    â”‚ Recall:    0.923 Â± 0.031                           â”‚  â”‚
â”‚    â”‚ F1-Score:  0.919 Â± 0.035                           â”‚  â”‚
â”‚    â”‚ Accuracy:  0.917 Â± 0.029                           â”‚  â”‚
â”‚    â”‚ Balanced:  0.921 Â± 0.032                           â”‚  â”‚
â”‚    â”‚ AUC:       0.963 Â± 0.017                           â”‚  â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸ“Š Model Architecture Details

### **QNN (Quantum Neural Network)**

```
ResNet18 Feature Extractor
        â†“
    128-dim features (frozen)
        â†“
    6-qubit quantum circuit
        â†“
    Quantum measurement (6 classical outputs)
        â†“
    Classical MLP (6 â†’ 64 â†’ 2)
        â†“
    Softmax

Training:
  âœ“ Cross-entropy loss (but with focal loss: Î³=2.5 on hard negatives)
  âœ“ Balanced mini-batches (equal samples per class)
  âœ“ 40 epochs, lr=1e-4
  âœ“ Threshold mode: 'balanced_min'
```

### **QSVC (Quantum Support Vector Classifier)**

```
ResNet18 Embeddings (512-dim)
        â†“
    Quantum Kernel Matrix (quantum feature map)
        â†“
    RBF Kernel (hybrid classical-quantum)
        â†“
    SVC with RBF kernel
        â†“
    CalibratedClassifierCV (Platt scaling)

Training:
  âœ“ SMOTE on training (balance minority class)
  âœ“ No SMOTE on validation (keep real distribution)
  âœ“ Hyperparameter grid: quantum_weight âˆˆ [0.15, 0.25, 0.35]
  âœ“ Grid scoring: 'balanced_accuracy' (not accuracy)
  âœ“ Threshold mode: 'balanced_min'
  âœ“ Calibration: fitted on validation with Platt scaling
```

### **Classical SVM Baseline**

```
ResNet18 Embeddings (512-dim)
        â†“
    PCA (10 components)
        â†“
    RBF SVM Classifier
        â†“
    Platt Scaling Calibrator

Training:
  âœ“ SMOTE on training
  âœ“ No SMOTE on validation
  âœ“ RBF kernel
  âœ“ Calibration: Platt on validation
```

### **Ensemble Voting**

```
Soft Voting:
  Ensemble Probability = 0.5 Ã— QNN_prob + 0.3 Ã— QSVC_prob + 0.2 Ã— SVM_prob

Final Prediction:
  if Ensemble_prob > learned_threshold:
      predict "Malignant" (class 1)
  else:
      predict "Benign" (class 0)
```

## ðŸ“ File Structure & Responsibilities

```
main_ensemble.py (THE MAIN RUNNER)
â”œâ”€ Loads data & sets up 5-fold CV
â”œâ”€ For each fold:
â”‚  â””â”€ Creates HeavyEnsembleClassifier
â”‚     â””â”€ Trains all 3 models
â”‚     â””â”€ Calibrates probabilities
â”‚     â””â”€ Optimizes ensemble threshold
â”‚     â””â”€ Evaluates on test
â””â”€ Aggregates across folds

ensemble_pipeline.py (HELPER CLASS)
â”œâ”€ EnsembleConfig: all hyperparameters
â””â”€ HeavyEnsembleClassifier: orchestrates 3 models
   â”œâ”€ train_qnn_fold(): trains QNN
   â”œâ”€ train_qsvc_fold(): trains QSVC
   â”œâ”€ train_classical_svm(): trains SVM
   â”œâ”€ optimize_ensemble_threshold(): finds best threshold
   â”œâ”€ predict(): applies ensemble
   â””â”€ predict_proba(): returns probabilities

diagnostics.py (OPTIONAL REPORTING)
â”œâ”€ Threshold sweep analysis
â”œâ”€ Per-model contributions
â””â”€ Calibration metrics

src/quantum_neural_network.py (QNN IMPLEMENTATION)
src/quantum_svc.py (QSVC IMPLEMENTATION)
src/metrics_utils.py (CENTRALIZED METRICS)
src/data_loader.py (DATA LOADING)
src/embedding_extractor.py (RESNET FEATURES)
```

## ðŸš€ Execution Flow

```bash
python main_ensemble.py

Step 1: Load ResNet embeddings
        âœ“ X_train: (7046, 512) | y_train: 11% malignant
        âœ“ X_val: (1482, 512) | y_val: 11% malignant
        âœ“ X_test: (1487, 512) | y_test: 11% malignant

Step 2: 5-Fold Cross-Validation (on X_train, y_train)
        For i = 1 to 5:
          Fold i:
            X_tr, y_tr (80% of fold)
            X_va, y_va (20% of fold, imbalanced distribution)

            â†’ HeavyEnsembleClassifier.train_qnn_fold()
              â””â”€ 40 epochs, focal loss, threshold tuning

            â†’ HeavyEnsembleClassifier.train_qsvc_fold()
              â””â”€ SMOTE training, calibrate validation

            â†’ HeavyEnsembleClassifier.train_classical_svm()
              â””â”€ SMOTE training, calibrate validation

            â†’ Optimize ensemble threshold on X_va
              â””â”€ Grid search: maximize min(precision, recall)

            â†’ Evaluate all 3 + ensemble on X_te
              â””â”€ Record 9 metrics per model/ensemble

        Aggregate: mean Â± std across 5 folds

Step 3: Output Results
        âœ“ results/ensemble_results.json
        âœ“ results/ensemble_results.csv
        âœ“ Console: Final scores with confidence intervals
```

## ðŸ“ˆ Key Design Decisions

| Component               | Decision                                       | Reason                                                      |
| ----------------------- | ---------------------------------------------- | ----------------------------------------------------------- |
| **Weighting**           | QNN 50%, QSVC 30%, SVM 20%                     | QNN has quantum advantage; QSVC hybrid; SVM as sanity check |
| **Calibration**         | Platt scaling on imbalanced validation         | Ensures probability estimates match real-world imbalance    |
| **Threshold**           | Learned per-fold on validation                 | Generalizes better than fixed 0.5                           |
| **Threshold Objective** | Balanced-min (maximize min(precision, recall)) | Avoids precision-recall trade-off, targets both equally     |
| **Training Balancing**  | SMOTE only (not balanced subsampling)          | SMOTE is more principled; subsampling wastes data           |
| **CV Strategy**         | 5-fold stratified                              | Ensures each fold has ~11% malignant class                  |

## âœ… Summary

- **Single Pipeline**: main_ensemble.py is the only script you run
- **All Models Integrated**: QNN, QSVC, SVM trained by HeavyEnsembleClassifier
- **Calibration**: All probabilities calibrated on imbalanced validation
- **Threshold Tuning**: Per-fold on validation, applied on test
- **Output**: Individual + ensemble metrics for transparency
- **Target**: >90% balanced scores (precision, recall, F1, accuracy)
